{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x228ead091d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 1: Data Loading and Preprocessing ===\n",
      "Training set size: 120 samples\n",
      "Testing set size: 30 samples\n",
      "Feature scaling completed using StandardScaler\n",
      "One-hot encoded labels shape: torch.Size([120, 3])\n",
      "Data preprocessing completed successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Data Loading and Preprocessing\n",
    "print(\"=== Task 1: Data Loading and Preprocessing ===\")\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target  # Target: species (0: setosa, 1: versicolor, 2: virginica)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Perform feature scaling (standardization) to normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed using StandardScaler\")\n",
    "\n",
    "# One-hot encoding equivalent using PyTorch (convert to tensors)\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_train_tensor = torch.LongTensor(y_train)  \n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create one-hot encoded versions for display (equivalent to to_categorical)\n",
    "y_train_onehot = F.one_hot(y_train_tensor, num_classes=3).float()\n",
    "y_test_onehot = F.one_hot(y_test_tensor, num_classes=3).float()\n",
    "\n",
    "print(f\"One-hot encoded labels shape: {y_train_onehot.shape}\")\n",
    "print(\"Data preprocessing completed successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 2: Neural Network Construction ===\n",
      "Neural Network Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Neural network construction completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Neural Network Construction\n",
    "print(\"=== Task 2: Neural Network Construction ===\")\n",
    "\n",
    "# Define the Neural Network class\n",
    "iris_net=nn.Sequential(\n",
    "    nn.Linear(4,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,3)\n",
    ")\n",
    "\n",
    "# Create the model instance\n",
    "model = iris_net\n",
    "\n",
    "print(\"Neural Network Architecture:\")\n",
    "print(model)\n",
    "print(\"Neural network construction completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 3: Model Compilation and Training ===\n",
      "Model compiled with:\n",
      "- Optimizer: Adam\n",
      "- Loss function: CrossEntropyLoss (Categorical Cross-entropy)\n",
      "\n",
      "Starting model training...\n",
      "Epoch [20/100], Loss: 0.3770, Accuracy: 89.17%\n",
      "Epoch [40/100], Loss: 0.2292, Accuracy: 94.17%\n",
      "Epoch [60/100], Loss: 0.1487, Accuracy: 95.83%\n",
      "Epoch [80/100], Loss: 0.1069, Accuracy: 96.67%\n",
      "Epoch [100/100], Loss: 0.0847, Accuracy: 97.50%\n",
      "Model training completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Model Compilation and Training\n",
    "print(\"=== Task 3: Model Compilation and Training ===\")\n",
    "\n",
    "# Define loss function and optimizer (equivalent to model.compile in Keras)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters()) \n",
    "\n",
    "print(\"Model compiled with:\")\n",
    "print(\"- Optimizer: Adam\")\n",
    "print(\"- Loss function: CrossEntropyLoss (Categorical Cross-entropy)\")\n",
    "\n",
    "# Create data loaders for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nStarting model training...\")\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    \n",
    "    # Print progress every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "print(\"Model training completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 4: Model Evaluation ===\n",
      "Test Loss: 0.1257\n",
      "Test Accuracy: 0.9333 (93.33%)\n",
      "\n",
      "Sample predictions vs actual:\n",
      "Predicted | Actual | Species\n",
      "------------------------------\n",
      "setosa    | setosa | setosa\n",
      "virginica | virginica | virginica\n",
      "versicolor | versicolor | versicolor\n",
      "versicolor | versicolor | versicolor\n",
      "setosa    | setosa | setosa\n",
      "versicolor | versicolor | versicolor\n",
      "setosa    | setosa | setosa\n",
      "setosa    | setosa | setosa\n",
      "virginica | virginica | virginica\n",
      "versicolor | versicolor | versicolor\n",
      "\n",
      "Final Model Accuracy on Test Set: 93.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Task 4: Model Evaluation ===\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Display some predictions vs actual\n",
    "print(\"\\nSample predictions vs actual:\")\n",
    "print(\"Predicted | Actual | Species\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(min(10, len(all_targets))):\n",
    "    pred_species = iris.target_names[all_predictions[i]]\n",
    "    true_species = iris.target_names[all_targets[i]]\n",
    "    print(f\"{pred_species:9} | {true_species:6} | {true_species}\")\n",
    "\n",
    "print(f\"\\nFinal Model Accuracy on Test Set: {test_accuracy*100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
